{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "freelance-score",
   "metadata": {
    "papermill": {
     "duration": 0.021827,
     "end_time": "2021-06-07T00:16:46.305199",
     "exception": false,
     "start_time": "2021-06-07T00:16:46.283372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Translation Aircraft Descriptions Using SageMaker Seq2Seq\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Download dataset and preprocess](#Download-dataset-and-preprocess)\n",
    "3. [Training the Machine Translation model](#Training-the-Machine-Translation-model)\n",
    "4. [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-charger",
   "metadata": {
    "papermill": {
     "duration": 0.021137,
     "end_time": "2021-06-07T00:16:46.347464",
     "exception": false,
     "start_time": "2021-06-07T00:16:46.326327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will train an aircraft product description model and will test the predictions on a few examples.\n",
    "\n",
    "SageMaker Seq2Seq algorithm is built on top of [Sockeye](https://github.com/awslabs/sockeye), a sequence-to-sequence framework for Neural Machine Translation based on MXNet. SageMaker Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-repair",
   "metadata": {
    "papermill": {
     "duration": 0.021033,
     "end_time": "2021-06-07T00:16:46.389485",
     "exception": false,
     "start_time": "2021-06-07T00:16:46.368452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. **This should be within the same region as the Notebook Instance, training, and hosting.**\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp in the cell below with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "separated-tomato",
   "metadata": {
    "isConfigCell": true,
    "papermill": {
     "duration": 0.026128,
     "end_time": "2021-06-07T00:16:46.437174",
     "exception": false,
     "start_time": "2021-06-07T00:16:46.411046",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import re\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sage = boto3.client(\"sagemaker\")\n",
    "\n",
    "# S3 bucket and prefix\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/ml-aircraft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "executive-celebrity",
   "metadata": {
    "papermill": {
     "duration": 0.88088,
     "end_time": "2021-06-07T00:16:47.386786",
     "exception": false,
     "start_time": "2021-06-07T00:16:46.505906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import re\n",
    "#from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-dryer",
   "metadata": {
    "papermill": {
     "duration": 0.021349,
     "end_time": "2021-06-07T00:16:47.429511",
     "exception": false,
     "start_time": "2021-06-07T00:16:47.408162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "discrete-message",
   "metadata": {
    "papermill": {
     "duration": 0.60087,
     "end_time": "2021-06-07T00:16:48.051780",
     "exception": false,
     "start_time": "2021-06-07T00:16:47.450910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# For plotting attention matrix later on\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-stress",
   "metadata": {
    "papermill": {
     "duration": 0.021444,
     "end_time": "2021-06-07T00:16:48.094706",
     "exception": false,
     "start_time": "2021-06-07T00:16:48.073262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download dataset and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-twenty",
   "metadata": {
    "papermill": {
     "duration": 0.060228,
     "end_time": "2021-06-07T00:17:28.943237",
     "exception": false,
     "start_time": "2021-06-07T00:17:28.883009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please note that it is a common practise to split words into subwords using Byte Pair Encoding (BPE). Please refer to [this](https://github.com/awslabs/sockeye/tree/master/tutorials/wmt) tutorial if you are interested in performing BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-hostel",
   "metadata": {
    "papermill": {
     "duration": 0.049397,
     "end_time": "2021-06-07T00:17:29.036709",
     "exception": false,
     "start_time": "2021-06-07T00:17:28.987312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since training on the whole dataset might take several hours/days, for this demo, let us train on the **first 10,000 lines only**. Don't run the next cell if you want to train on the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "involved-summary",
   "metadata": {
    "papermill": {
     "duration": 0.360556,
     "end_time": "2021-06-07T00:17:29.450066",
     "exception": false,
     "start_time": "2021-06-07T00:17:29.089510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # !head -n 50000 corpus.tc.before > corpus.tc.before.small\n",
    " # !head -n 50000 corpus.tc.after > corpus.tc.after.small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-atlas",
   "metadata": {
    "papermill": {
     "duration": 0.043187,
     "end_time": "2021-06-07T00:17:29.536593",
     "exception": false,
     "start_time": "2021-06-07T00:17:29.493406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's use the preprocessing script `create_vocab_proto.py` (provided with this notebook) to create vocabulary mappings (strings to integers) and convert these files to x-recordio-protobuf as required for training by SageMaker Seq2Seq.  \n",
    "Uncomment the cell below and run to see check the arguments this script expects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-karma",
   "metadata": {
    "papermill": {
     "duration": 0.043197,
     "end_time": "2021-06-07T00:17:29.722780",
     "exception": false,
     "start_time": "2021-06-07T00:17:29.679583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The cell below does the preprocessing. If you are using the complete dataset, the script might take around 10-15 min on an m4.xlarge notebook instance. Remove \".small\" from the file names for training on full datasets. Uncomment the the first executable line to see check the arguments this script expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "promising-likelihood",
   "metadata": {
    "papermill": {
     "duration": 1.137858,
     "end_time": "2021-06-07T00:17:30.903154",
     "exception": false,
     "start_time": "2021-06-07T00:17:29.765296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Building vocabulary from dataset: corpus.tc.before and corpus.tc.after\n",
      "INFO:__main__:Final vocabulary: 50004 types (min frequency 1, top 50000 types)\n",
      "INFO:__main__:Final vocabulary: 18109 types (min frequency 1, top 50000 types)\n",
      "INFO:__main__:Source vocabulary size: 50004 \n",
      "INFO:__main__:Vocabulary saved to \"vocab.src.json\"\n",
      "INFO:__main__:Target vocabulary size: 18109 \n",
      "INFO:__main__:Vocabulary saved to \"vocab.trg.json\"\n",
      "INFO:__main__:Spawning 1 encoding worker(s) for encoding train datasets!\n",
      "INFO:__main__:Processed 264047 lines for encoding to protobuf. 0 lines were ignored as they didn't have\n",
      "                any content in either the source or the target file!\n",
      "INFO:__main__:Completed writing the encoding queue!\n",
      "INFO:__main__:Encoding finished! Writing records to \"train.rec\"\n",
      "INFO:__main__:Processed input and saved to \"train.rec\"\n",
      "INFO:__main__:Spawning 1 encoding worker(s) for encoding validation datasets!\n",
      "INFO:__main__:Processed 10000 lines for encoding to protobuf. 0 lines were ignored as they didn't have\n",
      "                any content in either the source or the target file!\n",
      "INFO:__main__:Completed writing the encoding queue!\n",
      "INFO:__main__:Encoding finished! Writing records to \"val.rec\"\n",
      "INFO:__main__:Processed input and saved to \"val.rec\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.53 ms, sys: 6.53 ms, total: 10.1 ms\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "# python3 create_vocab_proto.py -h\n",
    "python3 create_vocab_proto.py \\\n",
    "        --train-source corpus.tc.before \\\n",
    "        --train-target corpus.tc.after \\\n",
    "        --val-source validation.before \\\n",
    "        --val-target validation.after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-health",
   "metadata": {
    "papermill": {
     "duration": 0.043095,
     "end_time": "2021-06-07T00:17:30.989500",
     "exception": false,
     "start_time": "2021-06-07T00:17:30.946405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The script will output 4 files, namely:\n",
    "- train.rec : Contains source and target sentences for training in protobuf format\n",
    "- val.rec : Contains source and target sentences for validation in protobuf format\n",
    "- vocab.src.json : Vocabulary mapping (string to int) for source language (English in this example)\n",
    "- vocab.trg.json : Vocabulary mapping (string to int) for target language (German in this example)\n",
    "\n",
    "Let's upload the pre-processed dataset and vocabularies to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entitled-sewing",
   "metadata": {
    "papermill": {
     "duration": 0.271489,
     "end_time": "2021-06-07T00:17:31.306497",
     "exception": true,
     "start_time": "2021-06-07T00:17:31.035008",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_to_s3(bucket, prefix, channel, file):\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    data = open(file, \"rb\")\n",
    "    key = prefix + \"/\" + channel + \"/\" + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "\n",
    "upload_to_s3(bucket, prefix, \"train\", \"train.rec\")\n",
    "upload_to_s3(bucket, prefix, \"validation\", \"val.rec\")\n",
    "upload_to_s3(bucket, prefix, \"vocab\", \"vocab.src.json\")\n",
    "upload_to_s3(bucket, prefix, \"vocab\", \"vocab.trg.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-german",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training the Machine Translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a738c7f-4bb9-4f7d-862e-b0de2e02aa0e",
   "metadata": {},
   "source": [
    "### Training job configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "false-alaska",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removable-tours",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker Seq2Seq container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/seq2seq:1 (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# container = get_image_uri(region_name, \"seq2seq\")\n",
    "container = sagemaker.image_uris.retrieve(\"seq2seq\",region_name) # ?????????\n",
    "\n",
    "print(\"Using SageMaker Seq2Seq container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "injured-thomas",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job training-seq2seq-aircraft-2022-09-03-14-48\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "job_name = \"training-seq2seq-aircraft-\" + strftime(\"%Y-%m-%d-%H-%M\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "create_training_params = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)},\n",
    "    \"ResourceConfig\": {\n",
    "        # Seq2Seq does not support multiple machines. Currently, it only supports single machine, multiple GPUs\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g4dn.2xlarge\",  # We suggest one of [\"ml.p2.16xlarge\", \"ml.p2.8xlarge\", \"ml.p2.xlarge\"]\n",
    "        \"VolumeSizeInGB\": 50,\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        # Please refer to the documentation for complete list of parameters\n",
    "        \"max_seq_len_source\": \"200\", # from 60\n",
    "        \"max_seq_len_target\": \"100\", # from 60\n",
    "        \"optimized_metric\": \"perplexity\", # from bleu\n",
    "        \"batch_size\": \"32\",  # Reduced from 64 (Please use a larger batch size (256 or 512) if using ml.p2.8xlarge or ml.p2.16xlarge)\n",
    "        \"rnn_num_hidden\": \"1024\", # from 512\n",
    "        \"num_layers_encoder\": \"3\", # from 1\n",
    "        \"num_layers_decoder\": \"3\", # from 1\n",
    "        \"num_embed_source\": \"1024\", # from 512\n",
    "        \"num_embed_target\": \"1024\", # from 512\n",
    "        \"checkpoint_frequency_num_batches\": \"1000\",\n",
    "        \"checkpoint_threshold\": \"3\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 48 * 3600},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"vocab\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/vocab/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de59e9a-54a0-4a22-bb7a-8d7ad77397d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training job execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-suspect",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "sagemaker_client = boto3.Session().client(service_name=\"sagemaker\")\n",
    "sagemaker_client.create_training_job(**create_training_params)\n",
    "\n",
    "status = sagemaker_client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(status)\n",
    "\n",
    "while status == 'InProgress':\n",
    "    print(\"Still training\")\n",
    "    time.sleep(60)\n",
    "    status = sagemaker_client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "\n",
    "\n",
    "print(status)\n",
    "# if the job failed, determine why\n",
    "if status == \"Failed\":\n",
    "    message = sagemaker_client.describe_training_job(TrainingJobName=job_name)[\"FailureReason\"]\n",
    "    print(\"Training failed with the following error: {}\".format(message))\n",
    "    raise Exception(\"Training job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-raise",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "> Now wait for the training job to complete and proceed to the next step after you see model artifacts in your S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-officer",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means translating sentence(s) from English to German.\n",
    "This section involves several steps,\n",
    "- Create model - Create a model using the artifact (model.tar.gz) produced by training\n",
    "- Create Endpoint Configuration - Create a configuration defining an endpoint, using the above model\n",
    "- Create Endpoint - Use the configuration to create an inference endpoint.\n",
    "- Perform Inference - Perform inference on some input data using the endpoint.\n",
    "\n",
    "### Create model\n",
    "We now create a SageMaker Model from the training output. Using the model, we can then create an Endpoint Configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "apparent-pleasure",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name :  training-seq2seq-aircraft-2022-09-03-14-48\n",
      "Model data :  s3://sagemaker-us-east-1-868430595087/sagemaker/ml-aircraft/training-seq2seq-aircraft-2022-09-03-14-48/output/model.tar.gz\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Cannot create already existing model \"arn:aws:sagemaker:us-east-1:868430595087:model/training-seq2seq-aircraft-2022-09-03-14-48\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 )\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Cannot create already existing model \"arn:aws:sagemaker:us-east-1:868430595087:model/training-seq2seq-aircraft-2022-09-03-14-48\"."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# requires sage, job_name\n",
    "# which was constructed from job_name = \"DEMO-seq2seq-aircraft-\" + strftime(\"%Y-%m-%d-%H\", gmtime())\n",
    "# DEMO-seq2seq-aircraft-2022-09-01-21\n",
    "\n",
    "# job_name = \"training-seq2seq-aircraft-2022-09-03-14-48\"\n",
    "\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_name = job_name\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model name : \", model_name)\n",
    "print(\"Model data : \", model_data) # this is the s3 path to the model.tar.gz\n",
    "\n",
    "primary_container = {\"Image\": container, \"ModelDataUrl\": model_data}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])\n",
    "\n",
    "# Models can be seen in the Sagemaker dashboard!!\n",
    "# They don't need to be created again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-triangle",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create endpoint configuration\n",
    "Use the model to create an endpoint configuration. The endpoint configuration also contains information about the type and number of EC2 instances to use when hosting the model.\n",
    "\n",
    "Since SageMaker Seq2Seq is based on Neural Nets, we could use an ml.p2.xlarge (GPU) instance, but for this example we will use a free tier eligible ml.m4.xlarge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "august-default",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-seq2seq-aircraft-2022-09-03-14-48\n",
      "AircraftEndpointConfig-2022-09-03-16-01-06\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:868430595087:endpoint-config/aircraftendpointconfig-2022-09-03-16-01-06\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "# requires sage, model_name\n",
    "\n",
    "# you can pick up the model name from the dashboard if you need to recreate the endpoint\n",
    "\n",
    "print(model_name)\n",
    "endpoint_config_name = \"AircraftEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-consciousness",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create endpoint\n",
    "Lastly, we create the endpoint that serves up model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 10-15 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rocky-hotel",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AircraftEndpoint-2022-09-03-16-01-12\n",
      "arn:aws:sagemaker:us-east-1:868430595087:endpoint/aircraftendpoint-2022-09-03-16-01-12\n",
      "Still creating\n",
      "Still creating\n",
      "Still creating\n",
      "Still creating\n",
      "Still creating\n",
      "Still creating\n",
      "Still creating\n",
      "Endpoint creation ended with EndpointStatus = InService\n",
      "CPU times: user 108 ms, sys: 8.91 ms, total: 117 ms\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = \"AircraftEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "# print(\"Status: \" + status)\n",
    "\n",
    "while status == 'Creating':\n",
    "    print(\"Still creating\")\n",
    "    time.sleep(60)\n",
    "    status = sage.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sage.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response[\"EndpointStatus\"]\n",
    "print(\"Endpoint creation ended with EndpointStatus = {}\".format(status))\n",
    "\n",
    "if status != \"InService\":\n",
    "    raise Exception(\"Endpoint creation failed.\")\n",
    "    \n",
    "# this doesn't actually wait for the endpoint creation, which takes 6-7 mins    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-behavior",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "If you see the message,\n",
    "> Endpoint creation ended with EndpointStatus = InService\n",
    "\n",
    "then congratulations! You now have a functioning inference endpoint. You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console.  \n",
    "\n",
    "We will finally create a runtime object from which we can invoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "laughing-first",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client(service_name=\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-present",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Perform Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-marriage",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Using JSON format for inference (Suggested for a single or small number of data instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-registrar",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Note that you don't have to convert string to text using the vocabulary mapping for inference using JSON mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cordless-ratio",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'target': 'Ilyushin Il-62M'}, {'target': 'Royal Aircraft Factory S.E.5a'}, {'target': 'Lockheed F-104G/S Starfighter'}, {'target': 'Aero L-39C Albatros'}, {'target': 'Supermarine Spitfire Mk.I +'}, {'target': 'General Dynamics F-16B/Lockheed-Martin Aardvark'}, {'target': 'Nothing'}, {'target': '- -'}, {'target': '-'}, {'target': 'Nothing'}, {'target': 'Nothing'}, {'target': 'Nothing'}, {'target': 'Nothing'}]}\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Ilyushin IL-62M Vinyl mask set (designed to be used with Zvezda kits) with some other shit\", \n",
    "             \"Royal-Aircraft-Factory SE.5a 'Hispano' Econo-Kit. Bagged kit. Royal Flying Corps staple biplane fighter\", \n",
    "             \"Lockheed F-104G/S Starfighter cockpit set (C2 seat) (designed to be used with Italeri kits)\",\n",
    "            \"Aero L-39C Albatros\",\n",
    "            \"Supermarine Spitfire Mk.I 2 canopy masks (exterior and interior) + 3 insignia masks (designed to be used with Hasegawa and Revell kits)\",\n",
    "             \"General-Dynamics F-111A/F-111D/F-111E/F-111F Aardvark wheels (designed to be used with Academy and Italeri kits\",\n",
    "             \"ARMORY ARAW48320 1/48 F-111E/F & EF-111A LATE type correct wheels weighted tyres\",\n",
    "             \"TRU02348 - Trumpeter 1:35 - ZU-23-2 Russian Anti-aircraft Gun\",\n",
    "             \"Trumpeter 1:35 - ZU-23-2 Russian Anti-aircraft Gun\",\n",
    "             \"ZU-23-2 Russian Anti-aircraft Gun\",\n",
    "             \"Russian Anti-aircraft Gun\",\n",
    "             \"Anti-aircraft Gun\",\n",
    "             \"Gun\"\n",
    "            ]\n",
    "\n",
    "# need to get this automatically from the previous step when appropriate\n",
    "# uncomment this when required\n",
    "# endpoint_name = \"AircraftEndpoint-2022-09-02-10-44-27\"\n",
    "\n",
    "payload = {\"instances\": []}\n",
    "for sent in sentences:\n",
    "    payload[\"instances\"].append({\"data\": sent})\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-simpson",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Retrieving the Attention Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-prisoner",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Passing `\"attention_matrix\":\"true\"` in `configuration` of the data instance will return the attention matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confirmed-celtic",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [{\"target\": \"Aero B-57B\", \"matrix\": [[0.9927489161491394, 0.00494384765625, 0.000732066051568836, 0.00010841900802915916, 0.000385119958082214, 0.00108169240411371], [0.7520669102668762, 0.12466021627187729, 0.03143960237503052, 0.008099870756268501, 0.027829887345433235, 0.05590333789587021]]}]}\n",
      "Source: can you drive a car ? \n",
      "Target: Aero B-57B\n"
     ]
    }
   ],
   "source": [
    "sentence = \"can you drive a car ?\"\n",
    "\n",
    "payload = {\"instances\": [{\"data\": sentence, \"configuration\": {\"attention_matrix\": \"true\"}}]}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "print(response)\n",
    "response = json.loads(response)[\"predictions\"][0]\n",
    "\n",
    "source = sentence\n",
    "target = response[\"target\"]\n",
    "attention_matrix = np.array(response[\"matrix\"])\n",
    "\n",
    "print(\"Source: %s \\nTarget: %s\" % (source, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proud-republican",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function for plotting the attentioan matrix\n",
    "def plot_matrix(attention_matrix, target, source):\n",
    "    source_tokens = source.split()\n",
    "    target_tokens = target.split()\n",
    "    assert attention_matrix.shape[0] == len(target_tokens)\n",
    "    plt.imshow(attention_matrix.transpose(), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.xlabel(\"target\")\n",
    "    plt.ylabel(\"source\")\n",
    "    plt.gca().set_xticks([i for i in range(0, len(target_tokens))])\n",
    "    plt.gca().set_yticks([i for i in range(0, len(source_tokens))])\n",
    "    plt.gca().set_xticklabels(target_tokens)\n",
    "    plt.gca().set_yticklabels(source_tokens)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "injured-youth",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(attention_matrix, target, source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-bidder",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Using Protobuf format for inference (Suggested for efficient bulk inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-spirit",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Reading the vocabulary mappings as this mode of inference accepts list of integers and returns list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "first-fluid",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:create_vocab_proto:Vocabulary (10661 words) loaded from \"vocab.src.json\"\n",
      "INFO:create_vocab_proto:Vocabulary (15980 words) loaded from \"vocab.trg.json\"\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import tempfile\n",
    "from record_pb2 import Record\n",
    "from create_vocab_proto import (\n",
    "    vocab_from_json,\n",
    "    reverse_vocab,\n",
    "    write_recordio,\n",
    "    list_to_record_bytes,\n",
    "    read_next,\n",
    ")\n",
    "\n",
    "source = vocab_from_json(\"vocab.src.json\")\n",
    "target = vocab_from_json(\"vocab.trg.json\")\n",
    "\n",
    "source_rev = reverse_vocab(source)\n",
    "target_rev = reverse_vocab(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-franklin",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"this is so cool\",\n",
    "    \"i am having dinner .\",\n",
    "    \"i am sitting in an aeroplane .\",\n",
    "    \"come let us go for a long drive .\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-kelly",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Converting the string to integers, followed by protobuf encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pregnant-shipping",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert strings to integers using source vocab mapping. Out-of-vocabulary strings are mapped to 1 - the mapping for <unk>\n",
    "sentences = [[source.get(token, 1) for token in sentence.split()] for sentence in sentences]\n",
    "f = io.BytesIO()\n",
    "for sentence in sentences:\n",
    "    record = list_to_record_bytes(sentence, [])\n",
    "    write_recordio(f, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "international-editor",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/x-recordio-protobuf\", Body=f.getvalue()\n",
    ")\n",
    "\n",
    "response = response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-andrews",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now, parse the protobuf response and convert list of integers back to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pacific-bloom",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_proto_response(received_bytes):\n",
    "    output_file = tempfile.NamedTemporaryFile()\n",
    "    output_file.write(received_bytes)\n",
    "    output_file.flush()\n",
    "    target_sentences = []\n",
    "    with open(output_file.name, \"rb\") as datum:\n",
    "        next_record = True\n",
    "        while next_record:\n",
    "            next_record = read_next(datum)\n",
    "            if next_record:\n",
    "                rec = Record()\n",
    "                rec.ParseFromString(next_record)\n",
    "                target = list(rec.features[\"target\"].int32_tensor.values)\n",
    "                target_sentences.append(target)\n",
    "            else:\n",
    "                break\n",
    "    return target_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sensitive-print",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weitere Informationen finden Sie hier .', 'wer sind die Nachfrage ? unterzeichnen .', 'jetzt hat die staatliche Bank an den internationalen Kapitalmrkten .']\n"
     ]
    }
   ],
   "source": [
    "targets = _parse_proto_response(response)\n",
    "resp = [\" \".join([target_rev.get(token, \"<unk>\") for token in sentence]) for sentence in targets]\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-bread",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Stop / Close the Endpoint (Optional)\n",
    "\n",
    "Finally, we should delete the endpoint before we close the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-dutch",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sage.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "papermill": {
   "default_parameters": {},
   "duration": 46.346339,
   "end_time": "2021-06-07T00:17:31.811195",
   "environment_variables": {},
   "exception": true,
   "input_path": "SageMaker-Seq2Seq-Translation-English-German.ipynb",
   "output_path": "/opt/ml/processing/output/SageMaker-Seq2Seq-Translation-English-German-2021-06-07-00-12-41.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-07T00:16:45.464856",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
